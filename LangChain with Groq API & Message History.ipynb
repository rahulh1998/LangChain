{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88a58608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Langsmith Tracing\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38df55a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001997D49E8D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001997D52A870>, model_name='groq/compound-mini', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from pprint import pprint\n",
    "\n",
    "llm = ChatGroq(model='groq/compound-mini')\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c3d5d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the rules of F1 in 10 lines:\n",
      "\n",
      "1. Formula 1 (F1) is a single-seater racing championship with 20 cars and 10 teams.\n",
      "2. Each team has 2 drivers competing in Grands Prix around the world.\n",
      "3. Cars are designed and built by teams, with engines supplied by 4 manufacturers.\n",
      "4. Qualifying sessions determine the starting grid for each Grand Prix.\n",
      "5. The objective is to complete a set number of laps in the shortest time possible.\n",
      "6. Drivers can make pit stops to change tires and refuel (not always necessary).\n",
      "7. Overtaking is allowed, but drivers must stay on track and avoid contact.\n",
      "8. Drivers are penalized for infractions like speeding in the pit lane or causing collisions.\n",
      "9. Points are awarded to the top 10 finishers: 25, 18, 15, 12, 10, 8, 6, 4, 2, 1.\n",
      "10. The driver and team with the most points at the end of the season are crowned World Champions.\n"
     ]
    }
   ],
   "source": [
    "from  langchain_core.output_parsers import StrOutputParser \n",
    "res = llm.invoke('Can you explain me about rules of f1 in 10 lines')\n",
    "parser = StrOutputParser()\n",
    "for line in parser.invoke(res).split(\"\\n\"):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e420224",
   "metadata": {},
   "source": [
    "### HumanMessages & System Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7ed5bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You look beautiful tonight translates to:\\n\\nTu as l'air magnifique ce soir!\\n\\nor, in a more formal tone:\\n\\nVous êtes magnifique ce soir!\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "                SystemMessage(content=\"Translate the user message to French\"),\n",
    "                HumanMessage(content=\"You look beautiful tonight!\")\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aab0b550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You look beautiful tonight translates to:\\n\\nTu as l'air magnifique ce soir!\\n\\nor, in a more formal tone:\\n\\nVous êtes magnifique ce soir!\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "str_parser = StrOutputParser()\n",
    "str_parser.invoke(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebdd9412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tu es belle ce soir!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using LCEL For Chaining\n",
    "\n",
    "chain1 = llm|str_parser\n",
    "chain1.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "124f9ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following into French', additional_kwargs={}, response_metadata={}), HumanMessage(content='Rahul is a really amazing person', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "gen_prompt  = \"Translate the following into {language}\"\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "                ('system',gen_prompt),\n",
    "                (\"user\", \"{text}\")\n",
    "])\n",
    "\n",
    "prompt.invoke({\"language\":\"French\",\"text\":\"Rahul is a really amazing person\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1a47678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rahul est une personne vraiment incroyable.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2  = prompt|llm|str_parser\n",
    "chain2.invoke({\"language\":\"French\",\"text\":\"Rahul is a really amazing person\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38fa0712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Rahul, and you mentioned you're a great AI Engineer!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 439, 'total_tokens': 471, 'completion_time': 0.058586, 'prompt_time': 0.069088, 'queue_time': 0.100453, 'total_time': 0.127674}, 'model_name': 'groq/compound-mini', 'system_fingerprint': None, 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--7f891b6b-d3b1-4197-a997-f54e69723a6f-0', usage_metadata={'input_tokens': 439, 'output_tokens': 32, 'total_tokens': 471})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Demonstration of how the History is stored \n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "llm.invoke([\n",
    "    HumanMessage(\"Hi Im Rahul, Im a great AI Engineer\"),\n",
    "    AIMessage(\"Hello Rahul! Nice to meet you! It's great to hear that you're an AI engineer. What kind of AI projects have you been working on lately\"),\n",
    "    HumanMessage(\"Hey whats my name and what do I Do?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a45383",
   "metadata": {},
   "source": [
    "### Chat Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80b3b7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Rahul! It's nice to meet you. Is there something I can help you with or would you like to chat?\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id :str)->BaseChatMessageHistory: # This is the base message history\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory() # This is the active session history\n",
    "    return store[session_id]\n",
    "\n",
    "with_chat_message_history = RunnableWithMessageHistory(llm,get_session_history)\n",
    "\n",
    "config = {\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "\n",
    "response = with_chat_message_history.invoke([HumanMessage(content=\"Hi My Name is Rahul\")],\n",
    "                                 config=config)\n",
    "\n",
    "op_parse = StrOutputParser()\n",
    "op_parse.invoke(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18be28a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9ad937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4725ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
