{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88a58608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Langsmith Tracing\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38df55a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rahul\\anaconda3\\envs\\genai\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000022F43D43470>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000022F43E8A540>, model_name='groq/compound-mini', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pprint import pprint\n",
    "\n",
    "llm = ChatGroq(model='groq/compound-mini')\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c3d5d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the basic rules of F1 in 10 lines:\n",
      "\n",
      "1. The Formula 1 World Championship consists of multiple Grands Prix races.\n",
      "2. Each team has two drivers competing in each race.\n",
      "3. The objective is to complete the most laps in the shortest time.\n",
      "4. Cars must meet technical regulations and weigh at least 733 kg.\n",
      "5. Drivers start from a grid position determined by qualifying laps.\n",
      "6. The driver with the fastest lap in qualifying gets pole position.\n",
      "7. A standard F1 race consists of 50-70 laps, depending on the circuit.\n",
      "8. Drivers can make pit stops to change tires and refuel (not allowed in some races).\n",
      "9. Overtaking is allowed, but drivers must follow rules to avoid collisions.\n",
      "10. Points are awarded to the top 10 finishers: 25, 18, 15, 12, 10, 8, 6, 4, 2, 1.\n"
     ]
    }
   ],
   "source": [
    "from  langchain_core.output_parsers import StrOutputParser \n",
    "res = llm.invoke('Can you explain me about rules of f1 in 10 lines')\n",
    "parser = StrOutputParser()\n",
    "for line in parser.invoke(res).split(\"\\n\"):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e420224",
   "metadata": {},
   "source": [
    "### HumanMessages & System Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7ed5bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Tu as l'air magnifique ce soir !\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "                SystemMessage(content=\"Translate the user message to French\"),\n",
    "                HumanMessage(content=\"You look beautiful tonight!\")\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aab0b550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Tu as l'air magnifique ce soir !\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "str_parser = StrOutputParser()\n",
    "str_parser.invoke(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebdd9412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You look beautiful tonight translates to:\\n\\nTu as l'air magnifique ce soir!\\n\\nor, in a more formal tone:\\n\\nVous Ãªtes magnifique ce soir!\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using LCEL For Chaining\n",
    "\n",
    "chain1 = llm|str_parser\n",
    "chain1.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "124f9ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following into French', additional_kwargs={}, response_metadata={}), HumanMessage(content='Rahul is a really amazing person', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "gen_prompt  = \"Translate the following into {language}\"\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "                ('system',gen_prompt),\n",
    "                (\"user\", \"{text}\")\n",
    "])\n",
    "\n",
    "prompt.invoke({\"language\":\"French\",\"text\":\"Rahul is a really amazing person\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1a47678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To translate the sentence \"Rahul is a really amazing person\" into French, I will use my language capabilities.\\n\\nThe translation is: \"Rahul est une personne vraiment incroyable.\"\\n\\nHere\\'s a breakdown of the translation:\\n\\n- \"Rahul\" remains the same as it\\'s a proper noun.\\n- \"is\" is translated to \"est\".\\n- \"a\" is translated to \"une\".\\n- \"really\" is translated to \"vraiment\".\\n- \"amazing\" is translated to \"incroyable\".\\n- \"person\" is translated to \"personne\".'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain2  = prompt|llm|str_parser\n",
    "chain2.invoke({\"language\":\"French\",\"text\":\"Rahul is a really amazing person\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38fa0712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Rahul, and you mentioned you're a great AI Engineer!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 439, 'total_tokens': 468, 'completion_time': 0.065011, 'prompt_time': 0.035566, 'queue_time': 0.524294, 'total_time': 0.100577}, 'model_name': 'groq/compound-mini', 'system_fingerprint': None, 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--e2d968fe-98db-4a86-a8f3-fc8ab25a5e05-0', usage_metadata={'input_tokens': 439, 'output_tokens': 29, 'total_tokens': 468})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "llm.invoke([\n",
    "    HumanMessage(\"Hi Im Rahul, Im a great AI Engineer\"),\n",
    "    AIMessage(\"Hello Rahul! Nice to meet you! It's great to hear that you're an AI engineer. What kind of AI projects have you been working on lately\"),\n",
    "    HumanMessage(\"Hey whats my name and what do I Do?\")\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a45383",
   "metadata": {},
   "source": [
    "### Chat Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80b3b7f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Rahul! It's nice to meet you. Is there something I can help you with or would you like to chat?\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id :str)->BaseChatMessageHistory: # This is the base message history\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory() # This is the active session history\n",
    "    return store[session_id]\n",
    "\n",
    "with_chat_message_history = RunnableWithMessageHistory(llm,get_session_history)\n",
    "\n",
    "config = {\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "\n",
    "response = with_chat_message_history.invoke([HumanMessage(content=\"Hi My Name is Rahul\")],\n",
    "                                 config=config)\n",
    "\n",
    "op_parse = StrOutputParser()\n",
    "op_parse.invoke(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18be28a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9ad937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4725ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
